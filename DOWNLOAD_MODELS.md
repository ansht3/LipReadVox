# Model Files Download Guide

Due to GitHub's file size limitations, some model files are not included in the repository. Please download them manually:

## Required Model Files

### 1. dlib Shape Predictor (95MB)

```bash
# Download the shape predictor file
curl -L -o model/shape_predictor_68_face_landmarks.dat.bz2 http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2

# Extract the file
cd model && bunzip2 shape_predictor_68_face_landmarks.dat.bz2
```

### 2. Trained Model Files

After running the training pipeline, these files will be generated:

- `model/lip_reader_3dcnn.h5` - Trained 3D CNN model (~16MB)
- `model/labels.npy` - Class labels (~240B)
- `model/training_history.png` - Training plots
- `model/confusion_matrix.png` - Evaluation metrics

## Quick Setup

Run the complete setup to generate all required files:

```bash
# 1. Set up environment
python -m venv lipread_env
source lipread_env/bin/activate
pip install -r requirements.txt

# 2. Download dlib model
curl -L -o model/shape_predictor_68_face_landmarks.dat.bz2 http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2
cd model && bunzip2 shape_predictor_68_face_landmarks.dat.bz2 && cd ..

# 3. Run demo to generate trained model
python quick_demo.py

# 4. Test real-time prediction
python src/predict.py
```

## File Structure After Setup

```
model/
├── shape_predictor_68_face_landmarks.dat  # Downloaded (95MB)
├── lip_reader_3dcnn.h5                    # Generated by training (~16MB)
├── labels.npy                             # Generated by training (~240B)
├── training_history.png                   # Generated by training
└── confusion_matrix.png                   # Generated by training
```

## Alternative: Use Pre-trained Model

If you want to skip training and use a pre-trained model, you can download it from a cloud storage service or run the quick demo which will generate all necessary files.
